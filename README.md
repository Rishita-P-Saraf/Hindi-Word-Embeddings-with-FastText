# Hindi Word Embeddings with FastText

This project demonstrates how to train **Hindi word embeddings** using **Facebookâ€™s FastText** library.  
It uses both **CBOW** and **Skip-gram** models to capture semantic and syntactic relationships between words.

---

## ğŸ“Œ Project Overview

1. **Dataset**
   - Hindi text is taken from the **Hindi Text Short Summarization Corpus** (`train.csv` and `test.csv`).
   - Each CSV contains an `article` column with Hindi text.

2. **Preprocessing**
   - Load CSV files using **pandas**.
   - Combine all text into a single string.
   - Clean unwanted characters:
     - Remove punctuation marks (`à¥¤!:.,;()_â€™?"\/@`).
     - Remove English characters `[a-zA-Z]`.
     - Remove special Unicode characters (`\u200d`, `\xa0`).
   - Normalize extra spaces.
   - Save processed text into `.txt` files (`training.txt`, `testing.txt`).

3. **Training FastText Models**
   - **CBOW Model:**
     ```python
     model = fasttext.train_unsupervised('training.txt', model='cbow')
     model.save_model("model_cbow.bin")
     ```
   - **Skip-gram Model:**
     ```python
     model = fasttext.train_unsupervised('training.txt', model='skipgram')
     model.save_model("model_skipgram.bin")
     ```

4. **Word Similarity Queries**
   - Get nearest neighbors of a word:
     ```python
     model.get_nearest_neighbors('à¤®à¥‹à¤¦à¥€')
     ```

---

## ğŸ› ï¸ Requirements

- Python 3.x
- Libraries:
  - `fasttext`
  - `numpy`
  - `pandas`
  - `re`

Install dependencies:
```bash
pip install fasttext numpy pandas
```
---

## ğŸš€ Usage
1. Preprocess the dataset:
   ```python
    preprocess('/kaggle/input/hindi-text-short-summarization-corpus/train.csv', 'training')
    preprocess('/kaggle/input/hindi-text-short-summarization-corpus/test.csv', 'testing')
   ```
3. Train embeddings:
   ```python
    model = fasttext.train_unsupervised('training.txt', model='cbow')
    model.save_model("model_cbow.bin")
    
    model = fasttext.train_unsupervised('training.txt', model='skipgram')
    model.save_model("model_skipgram.bin")
   ```
5. Query nearest neighbors:
   ```python
   model.get_nearest_neighbors('à¤­à¤¾à¤°à¤¤')
   ```
   
ğŸ“Š Example Output
- Nearest Neighbors of "à¤®à¥‹à¤¦à¥€":
   ```bash
   [(0.81, 'à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€'), 
   (0.76, 'à¤¸à¤°à¤•à¤¾à¤°'), 
   (0.74, 'à¤…à¤®à¤¿à¤¤'), 
   (0.73, 'à¤¯à¥‹à¤—à¥€')]
   ```

---

## ğŸ“‚ Project Structure
   ```python
    â”œâ”€â”€ training.txt            # Preprocessed training data
    â”œâ”€â”€ testing.txt             # Preprocessed testing data
    â”œâ”€â”€ model_cbow.bin          # Trained CBOW model
    â”œâ”€â”€ model_skipgram.bin      # Trained Skip-gram model
    â”œâ”€â”€ main.py                 # Preprocessing + training script
    â”œâ”€â”€ README.md               # Documentation
   ```
